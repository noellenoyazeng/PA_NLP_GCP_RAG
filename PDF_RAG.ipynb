{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34ae7127-a604-4318-b173-5c661f8c19cd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform==1.35.0 in ./.local/lib/python3.10/site-packages (1.35.0)\n",
      "Requirement already satisfied: google-cloud-documentai==2.20.1 in ./.local/lib/python3.10/site-packages (2.20.1)\n",
      "Requirement already satisfied: backoff==2.2.1 in /opt/conda/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.35.0) (1.34.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.35.0) (1.23.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.35.0) (3.20.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.35.0) (23.2)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.35.0) (2.14.0)\n",
      "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.35.0) (3.17.1)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.35.0) (1.11.0)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform==1.35.0) (2.0.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.35.0) (1.62.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.35.0) (2.27.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.35.0) (2.31.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.35.0) (1.48.1)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.35.0) (1.48.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.35.0) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.35.0) (2.7.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.35.0) (2.8.2)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform==1.35.0) (0.12.7)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.35.0) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.14 in /opt/conda/lib/python3.10/site-packages (from shapely<3.0.0dev->google-cloud-aiplatform==1.35.0) (1.23.5)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.35.0) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.35.0) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.35.0) (4.9)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.10/site-packages (from grpcio<2.0dev,>=1.33.2->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.35.0) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.35.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.35.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.35.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.35.0) (2023.11.17)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.35.0) (0.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade google-cloud-aiplatform==1.35.0 google-cloud-documentai==2.20.1 backoff==2.2.1 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4811b422-da69-4a49-8991-451feb9e8ed2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Automatically restart kernel after installs so that your environment can access the new packages\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "else:\n",
    "    # Otherwise, attempt to discover local credentials as described on https://cloud.google.com/docs/authentication/application-default-credentials\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1faf36c4-68cc-4b2f-a14b-3da47f8cf254",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 14:22:06.764218: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import backoff\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "from google.api_core.exceptions import ResourceExhausted\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.api_core.exceptions import AlreadyExists\n",
    "from google.cloud import documentai\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from typing import Dict, List\n",
    "import pandas as pd\n",
    "from logging import error\n",
    "import re\n",
    "import textwrap\n",
    "from typing import Tuple, List\n",
    "import vertexai\n",
    "from vertexai.language_models import TextEmbeddingModel, TextGenerationModel\n",
    "#import fitz \n",
    "import json\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c65f885-7824-4d81-91e6-3ee6e78e6dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Once the project is created in the console, extract the parameters here\n",
    "PROJECT_ID = !gcloud config get project\n",
    "PROJECT_ID = PROJECT_ID.n\n",
    "LOCATION = \"europe-west2\"\n",
    "LOCATION_DEPLOY = \"europe-west2\" #Location to deploy GCP resources\n",
    "\n",
    "#!gcloud services enable documentai.googleapis.com storage.googleapis.com aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b43bf492-0df6-499e-b7a9-bc224e742a71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Processor projects/59574701027/locations/europe-west2/processors/80ffc5b3df093287\n"
     ]
    }
   ],
   "source": [
    "# Edit these variables before running the code.\n",
    "project_id = PROJECT_ID\n",
    "\n",
    "# See https://cloud.google.com/document-ai/docs/regions for all options.\n",
    "location = LOCATION\n",
    "\n",
    "# Must be unique per project, e.g.: \"My Processor\"\n",
    "processor_display_name = \"proc\"\n",
    "\n",
    "# You must set the `api_endpoint` if you use a location other than \"us\".\n",
    "client_options = ClientOptions(api_endpoint=f\"{location}-documentai.googleapis.com\")\n",
    "\n",
    "\n",
    "#1. Create the processor: you can not create multiple processors with the same display name\n",
    "def create_processor(\n",
    "    project_id: str, location: str, processor_display_name: str\n",
    ") -> documentai.Processor:\n",
    "    client = documentai.DocumentProcessorServiceClient(client_options=client_options)\n",
    "\n",
    "    # The full resource name of the location\n",
    "    # e.g.: projects/project_id/locations/location\n",
    "    parent = client.common_location_path(project_id, location)\n",
    "\n",
    "    # Create a processor\n",
    "    return client.create_processor(\n",
    "        parent=parent,\n",
    "        processor=documentai.Processor(\n",
    "            display_name=processor_display_name, type_=\"OCR_PROCESSOR\" #we are using the pre-trained OCR processor\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "try:\n",
    "    processor = create_processor(project_id, location, processor_display_name)\n",
    "    print(f\"Created Processor {processor.name}\")\n",
    "except AlreadyExists as e:\n",
    "    print(\n",
    "        f\"Processor already exits, change the processor name and rerun this code. {e.message}\"\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "#2. Define process document function which takes the processor name and file path of the document and extracts the text from the document.  \n",
    "def process_document(\n",
    "    processor_name: str,\n",
    "    file_path: str,\n",
    ") -> documentai.Document:\n",
    "    client = documentai.DocumentProcessorServiceClient(client_options=client_options)\n",
    "\n",
    "    # Read the file into memory\n",
    "    with open(file_path, \"rb\") as image:\n",
    "        image_content = image.read()\n",
    "\n",
    "    # Load Binary Data into Document AI RawDocument Object\n",
    "    raw_document = documentai.RawDocument(\n",
    "        content=image_content, mime_type=\"application/pdf\"\n",
    "    )\n",
    "\n",
    "    # Configure the process request\n",
    "    request = documentai.ProcessRequest(name=processor_name, raw_document=raw_document)\n",
    "\n",
    "    result = client.process_document(request=request)\n",
    "\n",
    "    return result.document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c6fe750-0842-4353-856d-57c89570a20c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import fitz\n",
    "def split_and_save_pdf(input_pdf_path: str):\n",
    "    # Create a folder to store the split PDFs\n",
    "    output_folder = os.path.join(os.path.dirname(input_pdf_path), 'pdf_chunks')\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    pdf_paths = []\n",
    "\n",
    "    # Open the input PDF\n",
    "    with fitz.open(input_pdf_path) as pdf_document:\n",
    "        num_pages = pdf_document.page_count\n",
    "\n",
    "        # Calculate the number of files needed\n",
    "        #num_files = (num_pages + max_pages_per_file - 1) // max_pages_per_file\n",
    "\n",
    "        # Split the PDF into multiple files\n",
    "        for i in range(num_pages):\n",
    "            start_page, end_page = i, i+1 \n",
    "\n",
    "            pdf_writer = fitz.open()\n",
    "            pdf_writer.insert_pdf(pdf_document, from_page=start_page, to_page=end_page - 1)\n",
    "\n",
    "            output_pdf_path = os.path.join(output_folder, f'pdf_{i + 1}.pdf')\n",
    "            pdf_writer.save(output_pdf_path)\n",
    "\n",
    "            #print(f'Saved: {output_pdf_path}')\n",
    "            pdf_paths.append(output_pdf_path)\n",
    "            \n",
    "    waiting_time = len(pdf_paths)*2.52 \n",
    "    print(f'Estimated waiting time: {waiting_time} seconds')\n",
    "    return pdf_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a63258a0-6ed0-42b6-b53c-a7e46ebc7209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the desired parameters\n",
    "input_pdf_path = \"data/10_BMFashion_aa_2021-07-30.pdf\" # Replace with your actual input PDF path\n",
    "#max_pages_per_file = 15 # Set the desired maximum number of pages per file\n",
    "processor_name = processor.name # Assign the created processor name\n",
    "\n",
    "\n",
    "# 2. Iterate through the pdf chunks and extract and join their text\n",
    "def pdf_get_text_per_page(pdf_paths):\n",
    "    processor_name = processor.name \n",
    "    texts = []\n",
    "    page_numbers = list(range(1,len(pdf_paths)+1))\n",
    "    \n",
    "    for pdf_path in pdf_paths:\n",
    "        try: \n",
    "            document = process_document(processor_name, file_path = pdf_path)\n",
    "            texts.append(document.text)\n",
    "        except: \n",
    "            print('Document AI API resources exhausted. Waiting for 60 secs')\n",
    "            time.sleep(60)\n",
    "            document= process_document(processor_name, file_path = pdf_path)\n",
    "            texts.append(document.text)\n",
    "            \n",
    "    \n",
    "    df = pd.DataFrame({'Text':texts, 'PageNumber': page_numbers})\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_text_except_near_number(text):\n",
    "    pattern = r'(?<!\\d)\\n(?!\\d)'\n",
    "    splitted_text = re.split(pattern,text)\n",
    "    return ' '.join(splitted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09aef207-0053-4ac3-8af9-876e569b1b39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#3 create the embeddings for each pdf chunk\n",
    "# Call the GCP models\n",
    "generation_model = TextGenerationModel.from_pretrained(\"text-bison@002\")\n",
    "embedding_model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@003\")\n",
    "\n",
    "\n",
    "# This decorator is used to handle exceptions and apply exponential backoff in case of ResourceExhausted errors.\n",
    "# It means the function will be retried with increasing time intervals in case of this specific exception.\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(5))\n",
    "def text_generation_model_with_backoff(**kwargs):\n",
    "    return generation_model.predict(**kwargs).text\n",
    "\n",
    "\n",
    "def get_embedding(text):\n",
    "    get_embedding.counter += 1\n",
    "    try:\n",
    "        if get_embedding.counter % 100 == 0:\n",
    "            time.sleep(3)\n",
    "        return embedding_model.get_embeddings([text])[0].values #Send request to embedding model\n",
    "    except:\n",
    "        print('waiting for 60 secs')\n",
    "        time.sleep(60)\n",
    "        return embedding_model.get_embeddings([text])[0].values #Send request to embedding model\n",
    "    \n",
    "    \n",
    "\n",
    "#1. perform rag retrieval with the corresponding \n",
    "def get_context_from_question(\n",
    "    question: str, vector_store: pd.DataFrame, sort_index_value: int = 3\n",
    ") -> Tuple[str, pd.DataFrame]:\n",
    "    query_vector = np.array(get_embedding(question))\n",
    "    vector_store[\"dot_product\"] = vector_store[\"embedding\"].apply(\n",
    "        lambda row: np.dot(row, query_vector)\n",
    "    )\n",
    "    # Similarity matching by dot product \n",
    "    top_matched = vector_store.sort_values(by=\"dot_product\", ascending=False)[\n",
    "        :sort_index_value\n",
    "    ].index\n",
    "    \n",
    "    top_matched_df = vector_store.loc[top_matched, [\"PageNumber\", \"Text\"]]\n",
    "    context = \"\\n\".join(top_matched_df[\"Text\"].values)\n",
    "    \n",
    "    return context, top_matched_df\n",
    "\n",
    "def pdf_qa(embedded_df):\n",
    "    results =[]\n",
    "    \n",
    "    questions = [\"Give me the company name\",\n",
    "        \"Give me the scope 1 emisions\",\n",
    "                 \"Give me the scope 2 emissions\",\n",
    "                 \"Give me the scope 3 emissions\",\n",
    "                 \"Give me the total energy consumed in tCO2\"]\n",
    "    for question in questions: \n",
    "        # get the custom relevant chunks from all the chunks in vector store.\n",
    "        context, top_matched_df = get_context_from_question(\n",
    "        question,\n",
    "        vector_store=embedded_df,\n",
    "        sort_index_value=4,  # Top N results to pick from embedding vector search\n",
    "    )\n",
    "        prompt = f\"\"\" Answer the question as precise as possible using the provided context. \\n\\n\n",
    "            Context: \\n {context}?\\n\n",
    "            Question: \\n {question} \\n\n",
    "            Answer:\n",
    "  \n",
    "  \"\"\"\n",
    "        answer = text_generation_model_with_backoff(prompt=prompt)\n",
    "        results.append(print(question+\"\\n\\n\"+\"PaLM Predicted:\"+answer+\"\\n\\n\"))\n",
    "    return results, top_matched_df.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14d8b9c0-8d20-4e6c-8827-92d5db7e12c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pdf_rag_model(input_pdf_path):\n",
    "    #1. create a dataframe where each row is the text for each page of the pdf\n",
    "    text_per_page_df = pdf_get_text_per_page(split_and_save_pdf(input_pdf_path))\n",
    "    \n",
    "    #2. clean each page text of unecessary \\n\n",
    "    text_per_page_df['Text'] = text_per_page_df['Text'].apply(split_text_except_near_number)\n",
    "    \n",
    "    #3. calculate embeddings for each page text\n",
    "    get_embedding.counter = 0\n",
    "    text_per_page_df[\"embedding\"] = text_per_page_df[\"Text\"].apply(lambda x: get_embedding(x))\n",
    "    \n",
    "    #4. Q&A results and page info\n",
    "    results, info_page_number = pdf_qa(text_per_page_df)\n",
    "    return results, info_page_number\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b59299e9-acde-437e-9482-f56403b1dd0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# folder_path = 'data'\n",
    "\n",
    "# results_dict={}\n",
    "\n",
    "# star_index = 1\n",
    "# end_index = 3\n",
    "\n",
    "# for filename in os.listdir(folder_path):\n",
    "#     if filename.endswith('.pdf'):\n",
    "#         pdf_path = os.path.join(folder_path,filename)\n",
    "#         output = pdf_rag_model(pdf_path)\n",
    "#         results_dict[filename] = output\n",
    "            \n",
    "# print(results_dict)            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef40f8b5-44bb-4103-ba21-9a0283d2547d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in /opt/conda/lib/python3.10/site-packages (1.23.21)\n",
      "Requirement already satisfied: PyMuPDFb==1.23.9 in /opt/conda/lib/python3.10/site-packages (from PyMuPDF) (1.23.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4be8d291-c7d8-432e-9035-96a29f896785",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: IPython in /opt/conda/lib/python3.10/site-packages (8.20.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from IPython) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from IPython) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from IPython) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from IPython) (3.0.42)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from IPython) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from IPython) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.10/site-packages (from IPython) (5.9.0)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from IPython) (1.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from IPython) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->IPython) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->IPython) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->IPython) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->IPython) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->IPython) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->IPython) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->IPython) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33f18380-3833-436d-9180-ad3923da80cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e7e4480e2841a39423d284a397bf95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select PDF:', options=('data/27_Kilnbridge_aa_2021-06-30.pdf', 'data/28_TrustPayment_202…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb0ccbb08f34fda9a47f3adda7a6644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Custom Path:', placeholder='Enter PDF path')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf34d59dccd4570a39972c436b41a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Process PDF', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8e47f431134c5ba7c8b3f67fd7f8d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# build user interface\n",
    "\n",
    "# widgets display:\n",
    "\n",
    "#1. choice\n",
    "import ipywidgets as widgets \n",
    "from IPython.display import display, Image\n",
    "import fitz\n",
    "\n",
    "#pdf_rag_model\n",
    "\n",
    "pdf_paths = ['data/15_AppleBy_2022_09.pdf','data/16_Velji_Bhovan_2022_07.pdf','data/Underwooedmeat_aa_2021-10-31.pdf','data/NCRFinancialSolutions_aa_2020-12-31.pdf', 'data/27_Kilnbridge_aa_2021-06-30.pdf', 'data/28_TrustPayment_2021.pdf', 'data/29_HotelFolk_aa_2021.pdf']\n",
    "\n",
    "dropdown = widgets.Dropdown(options = pdf_paths, description = 'Select PDF:')\n",
    "input_path = widgets.Text(placeholder='Enter PDF path', description = 'Custom Path:')\n",
    "button = widgets.Button(description = 'Process PDF')\n",
    "output = widgets.Output()\n",
    "\n",
    "def render_pdf_page_as_image(pdf_path, page_number):\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    page_number = int(page_number)\n",
    "    page = pdf_document.load_page(page_number-1)\n",
    "    pix = page.get_pixmap(dpi=100)\n",
    "    return pix\n",
    "\n",
    "def on_button_click(b):\n",
    "    with output:\n",
    "        pdf_path = input_path.value if input_path.value else dropdown.value\n",
    "        #page_number = page_number_input.value\n",
    "        result, page_number = pdf_rag_model(pdf_path)\n",
    "        print(result)\n",
    "        \n",
    "        #render image and display PDF page as image\n",
    "        image = render_pdf_page_as_image(pdf_path, page_number)\n",
    "        display(Image(data=image.tobytes(), format='png'))\n",
    "        \n",
    "button.on_click(on_button_click)\n",
    "\n",
    "display(dropdown)\n",
    "display(input_path)\n",
    "display(button)\n",
    "display(output)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9225ee-dac5-4459-9809-468cea530aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m116",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m116"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
